%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       CARREGA DE LA CLASSE DE DOCUMENT                      %
%                                                                             %
% Les opcions admissibles son:                                                %
%      12pt / 11pt            (cos dels tipus de lletra; no feu servir 10pt)  %
%                                                                             %
% catalan/spanish/english     (llengua principal del treball)                 %
%                                                                             % 
% french/italian/german...    (si necessiteu fer servir alguna altra llengua) %
%                                                                             %
% listoffigures               (El document inclou un Index de figures)        %
% listoftables                (El document inclou un Index de taules)         %
% listofquadres               (El document inclou un Index de quadres)        %
% listofalgorithms            (El document inclou un Index d'algorismes)      %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,spanish,listoffigures,listoftables]{workluis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                     CODIFICACIO DEL FITXER FONT                             %
%                                                                             %
%    windows fa servir normalment 'ansinew'                                   %
%    amb linux es possible que siga 'latin1' o 'latin9'                       %
%    Pero el mes recomanable es fer servir utf8 (unicode 8)                   %
%                                          (si el vostre editor ho permet)    % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                        ALTRES PAQUETS I DEFINICIONS                         %
%                                                                             %
% Carregueu aci els paquets que necessiteu i declareu les comandes i entorns  %
%                                          (aquesta seccio pot ser buida)     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                        DADES DEL TREBALL                                    %
%                                                                             %
% titol, alumne, tutor i curs academic                                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Problema de regresión \\
         Resistencia a la compresión del hormigón}
\author{Luis Cabrero García}
\tutor{José María Valls Ferrán}
\curs{4º - Gr80}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              INICI DEL DOCUMENT                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%              RESUMS DEL TFG EN VALENCIA, CASTELLA I ANGLES                  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeindexes

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              CONTINGUT DEL TREBALL                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                  INTRODUCCIÓN                               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introducci\'on}

\par La presente práctica trata de abordar mediante el punto de vista de las redes de neuronas supervisadas la resolución de un problema real: la predicción de la resistencia del hormigón a la fuerza de compresión. Para ello disponemos de ocho variables de entrada: la edad del hormigón en días y siete variables que representan los componentes que forman el hormigón (cemento, escoria de alto horno, cenizas volantes, agua, superplastificante, agregado grueso y agregado fino). Estos datos han sido tomados del KEEL\cite{KEEL}.

\section{Motivaci\'on}

\par La utilidad de los modelos de regresión que vamos a aplicar de forma práctica es reseñable: nos permiten determinar el valor de la resistencia a la compresión del hormigón a partir de sus características, lo que tiene bastante interés a la hora de saber predecir la resistencia del material en construcciones reales. Si somos capaces de mirar un poco más alla somos capaces de ver que estos modelos de regresión lineal (Adaline) y no lineal (Perceptrón multicapa) son capaces de estimar salidas en función de los datos de entrada pero no solo en este caso sino en problemas de otra índole. Esto nos da una primera idea de la potencia de estos modelos.

\section{Objetivos}

\par Los objetivos de la práctica son: procesar los datos del KEEL\cite{KEEL}, implementar el aprendizaje del modelo Adaline en el lenguaje de programación deseado (en mi caso PHP), grabar en distintos ficheros los resultados del aprendizaje de la red, las salidas obtenidas y error cometido para el conjunto de test, y posteriormente realizar experimentación con MLP y el modelo Adaline. Posteriormente se realizará una comparación entre ambos modelos para ver en que casos un modelo puede aproximar mejor que el otro.

\section{Estructura de la memoria}

\par La memoria dispone de tres índices, uno para consultar cada una de las secciones y otros dos para figuras y tablas. En la memoria se puede encontrar un apartado general para el modelo Adaline y otro para el Perceptrón multicapa. Dentro de los respectivos apartados de cada modelo, se explica la base teórica de cada uno de ellos, se explica la implementación en el caso de Adaline, y en ambos se explica los distintos experimentos realizados y se razona el motivo por el que se consideran dichos experimentos como necesarios y suficientes. En las conclusiones se explican las diferencias entre ambos modelos y se comparan los resultados obtenidos en la experimentación. Al final de la memoria se indican las referencias bibliográficas consultadas para llevar a cabo el siguiente trabajo.

%\section{Notes bibliografiques} %%%%% Opcional

%????? ????????????? ????????????? ????????????? ????????????? ?????????????

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                         CAPITOLS (tants com calga)                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Modelo Adaline}

\par En este capítulo se va a explicar en primer lugar el modelo Adaline, se explicará la implementación que se ha llevado a cabo en PHP y el formato que se ha elegido para devolver las salidas del modelo. También se expermientará con distintos ciclos de aprendizaje y distintas razones de aprendizaje, y se verá el comportamiento de la red en todos los casos posibles, para ello se representará cada posible situación con un experimento para abordar todos los casos posibles.

\section{ADALINE: ADAptive LInear NEuron}

\par Es un tipo de red de neuronas artificiales desarrollada por Bernard Widrow y Ted Hoff. La red está compuesta por \textit{n} neuronas(\ref{fig:adaline}), con \textit{m} entradas. La salida de cada neurona se representa por la función de activación(\ref{eq:ej}) y representa el impacto de cada peso sobre las entradas, sumando el umbral de la neurona (\theta).

\begin{equation}\label{eq:ej}
y = \sum_{i=1}^{n}w_{i}*x_{i} + \theta
\end{equation}

\begin{figure}
\centering
\includegraphics[scale=0.5]{adaline}
\caption{Neurona ADALINE \cite{Adaline}}\label{fig:adaline}
\end{figure}

\par En el caso que nos ocupa(\ref{eq:ej2}), teniendo ocho entradas, la salida que se obtiene es la estimación de la resistencia del hormigón a la compresión. Los pesos aplicables a cada una de las entradas, junto con el umbral, se inicializan de manera aleatoria entre \textit{-0.5} y \textit{0.5}.

\begin{equation}\label{eq:ej2}
ConcreteCompressiveStrengthEst = \sum_{i=1}^{8}w_{i}*x_{i} + \theta
\end{equation}

\par El \textbf{aprendizaje} de la red, se realiza teniendo en cuenta la diferencia entre la salida deseada (adjunta como dato en los conjuntos de entrenamiento, test y validación) y la salida obtenida(\ref{eq:ej}). Teniendo en cuenta esta diferencia se trata de minimizar el error obtenido mediante la modificación de los pesos y el umbral. Para hallar el error cuadrático medio(\ref{eq:ej3}) se opera con todos los errores cuadráticos obtenidos en cada uno de los \textit{N} patrones. 

\begin{equation}\label{eq:ej3}
E = \frac{1}{N}* \sum_{p=1}^{N}(d^{p} - y^{p})^{2}
\end{equation}

\par Por último, la modificación de los pesos y umbral se realiza siguiendo la Regla Delta, que busca la minimización iterativa de la función de error(\ref{eq:ej3}), realizando un cambio a cada peso proporcional a la derivada del error, medida en el patrón actual, respecto del peso (\ref{eq:ej4}). El umbral también se modifica(\ref{eq:ej5}).

\begin{equation}\label{eq:ej4}
\Delta_{p}w_{j} = -\gamma\frac{\partial E^{p}}{\partial w_{j}} = \gamma*(d^{p} - y^{p})*x_{j}
\end{equation} 

\begin{equation}\label{eq:ej5}
\Delta_{p}\theta = \gamma*(d^{p} - y^{p})
\end{equation}

\par siendo $\gamma$ la razón o tasa de aprendizaje.

\par En este punto es importante resaltar que los datos deben \textbf{normalizarse}, \textbf{aleatorizarse} y \textbf{separados} en tres conjuntos de datos: \textbf{entrenamiento}, \textbf{validación} y \textbf{test}.

\begin{itemize}
\item \textbf{Datos de entrenamiento}: (70\%  del  total  de  datos) para  realizar  el aprendizaje de la red. 
\item \textbf{Datos de validación}: (15\%  del  total  de  datos) utilizados para elegir los  valores  óptimos  de los parámetros  de  la  red  (razón  de aprendizaje, número de ciclos, número de neuronas).
\item \textbf{Datos de test}: (15\%  del  total  de  datos) para evaluar la capacidad de generalización de la red.
\end{itemize}

\section{Implementación del modelo}

\par El modelo se ha decidido implementar en PHP por estar el autor familiarizado con dicho lenguaje y por la tremenda facilidad que ofrece a la hora de hacer cambios de tipo. En el fichero adaline.php se define la clase Adaline, que tiene atributos que caracterizan a la red de una sola neurona. Se leen los parámetros pasados por terminal y se ejecuta el aprendizaje de la red. Posteriormente se pasa el conjunto de validación y por último se pasa el conjunto de test.

\begin{lstlisting}
<?php

   //EJECUCION: php entrenamiento.php <tasa_aprendizaje> <num_ciclos>

   include 'adaline.php';
   $tasa_aprendizaje = $argv[1];
   $num_ciclos = $argv[2];
   $adaline = new Adaline($tasa_aprendizaje);
   $adaline->ejecutaradaline($num_ciclos);

?>
\end{lstlisting}

\par \textbf{Especificación de los métodos implementados}

\begin{itemize}
\item \textit{construct}. Parámetro: tasa de aprendizaje. Inicializa pesos y umbral de manera aleatoria, inicializa la tasa de aprendizaje, inicializa los arrays necesarios.
\item \textit{aprendizaje}. Parámetros: fichero a utilizar y ciclo. Realiza el aprendizaje de la red utilizando los datos de entrenamiento provenientes de un fichero csv.
\item \textit{error}. Parámetros: fichero a utilizar y ciclo. Calcula el error producido en un ciclo de entrenamiento sin modificar los pesos ni el umbral.
\item \textit{errorvalidacion}. Parámetros: fichero a utilizar y ciclo. Calcula el error producido en un ciclo de validación sin modificar los pesos ni el umbral.
\item \textit{errortest}. Parámetro: fichero a utilizar. Calcula el error cuadrático medio sobre el conjunto de los datos de test.
\item \textit{resultados}. Parámetros: carpeta, ciclo y número de ciclos. Muestra en un fichero HTML las salidas obtenidas para el conjunto de entrenamiento y validación normalizadas y desnormalizadas.
\item \textit{mostrarerrores}. Parámetros: carpeta y número de ciclos. Muestra en un fichero HTML los errores cuadráticos medios por cada ciclo para entrenamiento y validación, el valor del error cuadrático medio para el conjunto de test, los pesos y umbral resultantes tras aprendizaje y las salidas desnormalizadas de test.
\item \textit{datostest}. Parámetros: carpeta y número de ciclos. Muestra en un fichero HTML los errores sobre el conjunto de test normalizado y sin normalizar, muestra también una gráfica comparando las salidas obtenidas con las esperadas.
\end{itemize}

\section{Experimentación realizada}

\par La experimentación realizada en Adaline se basa en ir variando la razón de aprendizaje ($\gamma$) y el número de ciclos de ejecución. Iremos extrayendo ciertas conclusiones en función de los valores posibles de $\gamma$, entre 0 y 1 y los ciclos de ejecución, que pueden ser desde 1 al número que se quiera indicar.

\par \underline{\textbf{Experimentaciones}}

\par \textbf{$\gamma = 0.8$ y $ciclos = 500$}

\par Con una tasa de 0.8 y 500 ciclos la red "no aprende" (\ref{fig:8500}) dado que comienza cometiendo un error y en el ciclo inmediatamente posterior el error aumenta, tendencia que continúa hasta que el error se estabiliza en un valor elevado, por tanto considero de poco interés este experimento. El error obtenido sobre el conjunto de test es de 0.49219936325144.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{8500}
\caption{Gráfica Adaline 0.8 - 500}\label{fig:8500}
\end{figure}

\par \textbf{$\gamma = 0.2$ y $ciclos = 500$}

\par Con una tasa de 0.2 y 500 ciclos (\ref{fig:2500}) se produce un claro sobreaprendizaje dado que la red es capaz de generalizar el conjunto de entrenamiento con un error cuadrático medio que se estabiliza en torno a 0.021043565092019 mientras que el conjunto de validación se estabiliza en torno a 0.021394445575013. Como vemos la diferencia es muy pequeña pero digamos que en este valor se comienza a producir el sobreaprendizaje, situación que no deseamos porque esto indica que la red no será capaz de generalizar bien datos que no conozca. El error de test es de 0.023142903383433.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{2500}
\caption{Gráfica Adaline 0.2 - 500}\label{fig:2500}
\end{figure}

\par \textbf{$\gamma = 0.15$ y $ciclos = 500$, $\gamma = 0.1$ y $ciclos = 500$}

\par Con una tasa de 0.15 y 500 ciclos se sigue produciendo sobreaprendizaje pero se puede observar que según se va disminuyendo la tasa de aprendizaje, el valor absoluto de la diferencia entre ambos errores va disminuyendo. También va disminuyendo el error de test que ahora se sitúa en 0.021433296435724. Esta tendencia se puede comprobar con la experimentación realizada para $\gamma = 0.1$ y $ciclos = 500$ (\ref{fig:1500}). El error de entrenamiento se estabiliza en 0.017396882217266 y el de validación en 0.018214407942476. El error producido en test en este caso es de 0.020000915138424. En este caso, con $\gamma = 0.1$ sigue produciendose sobreaprendizaje.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{1500}
\caption{Gráfica Adaline 0.1 - 500}\label{fig:1500}
\end{figure}

\par \textbf{$\gamma = 0.0001$ y $ciclos = 20000$}

\par Con una tasa muy pequeña ($\gamma = 0.0001$) son necesarios cerca de 20000 ciclos (\ref{fig:000120000}) para conseguir que los errores de validación y entrenamiento se estabilicen. Se obtienen 0.016186448864616 y 0.016999895299418 como errores estabilizados en entrenamiento y validación respectivamente. El error producido sobre el conjunto de test es 0.019147481314295.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{000120000}
\caption{Gráfica Adaline 0.0001 - 20000}\label{fig:000120000}
\end{figure}

\section{Resumen experimentación Adaline}

\begin{table}[H]
\centering
\caption{Resumen experimentación Adaline}
\label{tb:tb1}
\begin{tabular}{lllll}
\hline
\multicolumn{1}{|l|}{Tasa de aprendizaje} & Error entrenamiento & Error validación  & Error test        \\ \hline \hline
0.8                                       & 0.47269316589935    & 0.49962652341666  & 0.49219936325144  \\
0.2                                       & 0.021043565092019   & 0.021394445575013 & 0.023142903383433 \\
0.1                                       & 0.017396882217266   & 0.018214407942476 & 0.020000915138424 \\
0.0001                                    & 0.016186448864616   & 0.016999895299418 & 0.019147481314295 \\ \hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{bestadaline}
\caption{Salidas obtenidas vs salidas deseadas para tasa de aprendizaje 0.0001}\label{fig:bestadaline}
\end{figure}

\par Como vemos, el mejor experimento realizado es aquel que minimiza el error cuadrático medio, esto es, el realizado con tasa de aprendizaje 0.0001, por lo que se muestran las salidas obtenidas frente a las deseadas en dicho experimento. Podemos ver que para algunas de las salidas el modelo aproxima casi a la perfección pero para otras hay grandes diferencias, en esas diferencias es en las que se genera el error que en este caso se eleva a 123.26694496161, valor desnormalizado. Posteriormente evaluaremos el MLP y veremos si estos valores son mejorables \footnote{Para ver los valores en detalle acudir a los resultados adjuntos en formato HTML}.

\chapter{Modelo Perceptrón Multicapa}

\par En este capítulo se explicará el modelo del Perceptrón multicapa, se explicará la experimentación realizada sobre el script básico proporcionado en lenguaje R, se resumirá la experimentación y se tratará de explicar los resultados. Para realizar la experimentación se irán variando tanto la tasa de aprendizaje como el número de neuronas ocultas.

\section{Perceptron Multicapa (MLP)}

\par Es una red de neuronas artificiales formada por múltiples capas (\ref{fig:mlp}). A diferencia del modelo Adaline, resuelve problemas que no son linealmente separables. Además, se ha demostrado que es un aproximador universal, es decir,  cualquier función contínua en el espacio $\mathbb{R}^n$ puede aproximarse con este modelo. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{mlp}
\caption{Red Perceptrón multicapa \cite{MLP}}\label{fig:mlp}
\end{figure}

\par La arquitectura está distribuida en tres tipos de neuronas: neuronas de entrada, que únicamente reciben las entradas y las propagan a la siguiente capa, las neuronas ocultas, que procesan de manera no lineal las entradas, y las neuronas de salida, que devuelven las salidas al exterior.

\par Teniendo dos neuronas \textit{i} y \textit{j}:

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{mlpesquema}
\caption{Esquema MLP \cite{MLP}}\label{fig:esquema}
\end{figure}

\par Los pesos y el umbral (\ref{eq:ej6}) se expresan en forma matricial, e influyen en la activación de la neurona perteneciente a la capa siguiente. Las neuronas de entrada simplemente tienen su activación equivalente a la entrada que reciben, sin embargo, tanto las neuronas de la capa de salida (\ref{eq:ej8}) como las neuronas de las capas ocultas (\ref{eq:ej7}) necesitan computar los pesos y sus entradas sumándoles el umbral.

\begin{equation}\label{eq:ej6}
W^c = (w_{ij}^c) = \begin{pmatrix}
w_{11}^c & w_{12}^c & ... & w_{1n_{c+1}}^c\\ 
w_{21}^c & w_{22}^c & ... & w_{2n_{c+1}}^c\\ 
... & ... & & ...\\ 
w_{n_{c}1}^c & w_{n_{c}2}^c & ... & w_{n_{c}n_{c+1}}^c 
\end{pmatrix}  ,  U^c = (u_{i}^c) = \begin{pmatrix}
u_{1}^c\\ 
u_{2}^c\\ 
...\\ 
u_{n_{c}}^c 
\end{pmatrix}
\end{equation}

\begin{equation}\label{eq:ej7}
a_{i}^c = f(\sum_{j=1}^{n_{c-1}}w_{ji}^{c-1}*a_{j}^{c-1} + u_{i}^{c})
\end{equation} 

\begin{equation}\label{eq:ej8}
y_{i} = a_{i}^c = f(\sum_{j=1}^{n_{c-1}}w_{ji}^{c-1}*a_{j}^{c-1} + u_{i}^{c})
\end{equation} 

\par Siendo $f$ la función de activación. Las funciones más utilizadas son la función sigmoidal ($f_{1}(x) = \frac{1}{1+e^{-x}}$) y la tangente hiperbólica ($f_{2}(x) = \frac{1-e^{-x}}{1+e^{-x}}$). El aprendizaje de la red se realiza de forma semejante que en Adaline, pero no entraremos en detalle en esta ocasión \cite{MLP}.

\section{Experimentación realizada}

\par En cuanto a la experimentación realizada se ha prestado especial atención en conseguir una capacidad de generalización adecuada. Esto es: no nos interesa conseguir que la red sea capaz de estimar valores del conjunto de entrenamiento pero que cuando entren datos de un conjunto nuevo, no sea capaz de generalizarlos. Esta situación es conocida como \textbf{sobreaprendizaje}. La siguiente figura (\ref{fig:sobreaprendizaje}) tomada de las transparencias de los profesores de la asignatura ilustra muy bien este comportamiento no deseado. Aun así trataremos de ver una situación de sobreaprendizaje en la experimentación para tratar de explicar el motivo de este comportamiento.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{sobreaprendizaje}
\caption{Sobreaprendizaje en MLP \cite{MLP}}\label{fig:sobreaprendizaje}
\end{figure}

\par Esta situación se puede evitar renunciando a cierta capacidad de generalización sobre el conjunto de entrenamiento, si esto nos va a llevar a una mejor capacidad de generalización sobre otros conjuntos de datos como pudieran ser test o validación. Esto nos aboca a dos posibles situaciones: estabilizar los errores de entrenamiento y test (el aprendizaje ha terminado con éxito) o bien que el error de entrenamiento se estabiliza y el error de test se dispara (se ha producido sobreaprendizaje y el modelo no generaliza bien los datos). Si inicializamos un modelo MLP con demasiadas neuronas ocultas o pesos, o incluso demasiados ciclos, el modelo en su aprendizaje será capaz de generalizar con mucha exactitud el conjunto de entrenamiento. Sin embargo existe la posibilidad de que al presentar al modelo datos de otro conjunto, su capacidad de generalización resulte en fracaso (\ref{fig:sobreaprendizaje}). 

\par \underline{\textbf{Experimentaciones}}

\par \textbf{$\gamma = 0.8$, $ciclos = 10000$ y $n_{ocultas} = 50$ ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}

\par Con una tasa de 0.8, bastante elevada, 50 neuronas en la capa oculta y 10000 ciclos (\ref{fig:500810000sig}), lo que tenemos es una clara situación de sobreaprendizaje. El modelo es capaz de generalizar bien el conjunto de entrenamiento con un error de 0.00215141436100276 mientras que en test se produce un error de 0.00305097518407372. Este experimento se ha realizado utilizando la función de activación sigmoidal. Es de suponer que si incrementamos el número de capas ocultas el sobreaprendizaje se acentuaría y la gráfica sería más evidente.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{500810000sig}
\caption{Gráfica MLP 0.8 - 50 ocultas - 10000 ciclos ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}\label{fig:500810000sig}
\end{figure}

\par \textbf{$\gamma = 0.8$, $ciclos = 10000$ y $n_{ocultas} = 50$ ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}

\par Con una tasa de 0.8, bastante elevada, 50 neuronas en la capa oculta y 10000 ciclos (\ref{fig:500810000tan}), lo que tenemos es una clara situación de sobreaprendizaje. El modelo es capaz de generalizar bien el conjunto de entrenamiento con un error de 0.00429123031163413 mientras que en test se produce un error de 0.00604587325351324. Este experimento se ha realizado utilizando la función de activación tangente hiperbólica. A simple vista vemos la diferencia entre las dos gráficas (\ref{fig:500810000tan} y \ref{fig:500810000sig}), si nos damos cuenta, a parte de que el error producido es prácticamente el doble utilizando la tangente hiperbólica, esta segunda función presenta un comportamiento bastante inestable, al necesitar un mínimo de 3000 ciclos para comenzar su estabilización, mientras que la sigmoidal entra en esta fase a partir del ciclo 700. Podemos afirmar que en este caso la sigmoidal genera mejor modelo que la tangente hiperbólica.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{500810000tan}
\caption{Gráfica MLP 0.8 - 50 ocultas - 10000 ciclos ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}\label{fig:500810000tan}
\end{figure}

\par \textbf{$\gamma = 0.2$, $ciclos = 6000$ y $n_{ocultas} = 50, 50$ ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}

\par Con una tasa de 0.2, 50 neuronas en dos capas ocultas y 6000 ciclos (\ref{fig:5050026000sig}), lo que tenemos es sobreaprendizaje de nuevo. El modelo es capaz de generalizar bien el conjunto de entrenamiento con un error de 0.00283018784738848 mientras que en test se produce un error de 0.00431462177153583. Este experimento se ha realizado utilizando la función de activación sigmoidal.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{5050026000sig}
\caption{Gráfica MLP 0.2 - 50,50 ocultas - 6000 ciclos ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}\label{fig:5050026000sig}
\end{figure}

\par \textbf{$\gamma = 0.2$, $ciclos = 6000$ y $n_{ocultas} = 50, 50$ ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}

\par Con una tasa de 0.2, 50 neuronas en dos capas ocultas y 6000 ciclos (\ref{fig:500810000tan}), lo que tenemos es sobreaprendizaje más evidente que utilizando la función sigmoidal. El modelo es capaz de generalizar bien el conjunto de entrenamiento con un error de 0.000889548028478484 mientras que en test se produce un error de 0.00346949202753306. Este experimento se ha realizado utilizando la función de activación tangente hiperbólica. Resulta evidente que no es adecuada la utilización de esta función.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{500810000tan}
\caption{Gráfica MLP 0.2 - 50,50 ocultas - 6000 ciclos ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}\label{fig:500810000tan}
\end{figure}

\par \textbf{$\gamma = 0.1$, $ciclos = 2000$ y $n_{ocultas} = 100, 50$ ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}

\par Con una tasa de 0.1, 50 y 100 neuronas en dos capas ocultas y 2000 ciclos (\ref{fig:10050012000sig}), tenemos un buen modelo. El modelo es capaz de generalizar bien el conjunto de entrenamiento con un error de 0.00415175928712051 mientras que en test se produce un error de 0.00448553303982486. Utilizando la función sigmoidal, vemos que hemos renunciado a cierta capacidad de generalización sobre el conjunto de entrenamiento, a cambio de mejorar la generalización sobre otros conjuntos.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{10050012000sig}
\caption{Gráfica MLP 0.1 - 100,50 ocultas - 2000 ciclos ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}\label{fig:10050012000sig}
\end{figure}

\par \textbf{$\gamma = 0.1$, $ciclos = 2000$ y $n_{ocultas} = 100, 50$ ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}

\par Con una tasa de 0.1, 50 y 100 neuronas en dos capas ocultas y 2000 ciclos (\ref{fig:10050012000tan}), utilizando la función tangente hiperbólica vemos que el error de test se dispara y si aumentásemos los ciclos tendríamos que el error de test diverge. Por tanto no es adecuado este modelo.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{10050012000tan}
\caption{Gráfica MLP 0.1 - 100,50 ocultas - 2000 ciclos ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}\label{fig:10050012000tan}
\end{figure}

\par \textbf{$\gamma = 0.0001$, $ciclos = 40000$ y $n_{ocultas} = 100, 50, 25$ ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}

\par Con una tasa de 0.0001, 100, 50 y 25 neuronas en tres capas ocultas y 40000 ciclos (\ref{fig:10050250000140000sig}), generaliza el conjunto de entrenamiento con un error de 0.0381546433606143, y el conjunto de test con un error de 0.039593033458852. Se ve que el modelo no es en absoluto apropiado puesto que el error es demasiado elevado y hay demasiada diferencia entre ambos errores.


\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{10050250000140000sig}
\caption{Gráfica MLP 0.0001 - 100,50,25 ocultas - 40000 ciclos ($f_{a}(x) = \frac{1}{1+e^{-x}}$)}\label{fig:10050250000140000sig}
\end{figure}

\par \textbf{$\gamma = 0.0001$, $ciclos = 40000$ y $n_{ocultas} = 100, 50, 25$ ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}

\par Con una tasa de 0.0001, 100, 50 y 25 neuronas en tres capas ocultas y 40000 ciclos (\ref{fig:10050250000140000tan}), utilizando la función tangente hiperbólica tenemos un error sobre el conjunto de entrenamiento de 0.00528260390284608
, un error sobre el conjunto de test de 0.00569856426934457. Vemos que los errores son semejantes. Comparando en este caso ambas funciones, vemos que en este caso particular, la función de activación tangente hiperbólica genera mejor modelo que la sigmoidal.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{10050250000140000tan}
\caption{Gráfica MLP 0.0001 - 100,50,25 ocultas - 40000 ciclos ($f_{a}(x) = \frac{1-e^{-x}}{1+e^{-x}}$)}\label{fig:10050250000140000tan}
\end{figure}

\section{Resumen experimentación Perceptrón Multicapa}

\begin{table}[H]
\centering
\caption{Resumen experimentación MLP}
\label{tb:tb2}
\resizebox{15cm}{!} {
\begin{tabular}{lllll}
\hline
\multicolumn{1}{|l|}{Tasa de aprendizaje} & Error entrenamiento & Error validación    & Error test        \\ \hline \hline
0.8 50 ocultas sigmoidal                  & 0.00215141436100276  & 0.00517340674087032 & 0.00305097518407372  \\
0.8 50 ocultas tangente hiperbólica       & 0.00429123031163413  & 0.0052114219011533  & 0.00604587325351324  \\
0.2 50, 50 ocultas sigmoidal              & 0.00283018784738848  & 0.00485646757920353 & 0.00431462177153583  \\
0.2 50, 50 ocultas tangente hiperbólica   & 0.000889548028478484 & 0.00553734379737086 & 0.00346949202753306  \\
0.1 100, 50 ocultas sigmoidal             & 0.00415175928712051  & 0.0050566079914164  & 0.00448553303982486  \\
0.1 100, 50 ocultas tangente hiperbólica  & 0.00131125349800932  & 0.00502077763421073 & 0.00533692446637476  \\
0.0001 100, 50, 25 ocultas sigmoidal             & 0.0381546433606143  & 0.0426178103593746  & 0.039593033458852  \\
0.0001 100, 50, 25 ocultas tangente hiperbólica  & 0.00528260390284608 & 0.00663522559427817 & 0.00569856426934457 \\ \hline
\end{tabular}
}
\end{table}

\par En la tabla \ref{tb:tb2} se observa claramente que el mejor modelo es el último considerado, puesto que a pesar de que presenta un error mayor que el primero, es capaz de mantener la diferencia entre los errores muy baja. Esto significa que si siguiésemos presentando conjuntos diferentes de datos sería capaz de generalizarlos correctamente. Por ello se considera que es el mejor modelo. Las salidas obtenidas vs las salidas deseadas las podemos apreciar en la gráfica \ref{fig:bestmlp}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{bestmlp}
\caption{Salidas obtenidas vs salidas deseadas para tasa de aprendizaje 0.0001 neuronas: 100, 50, 25}\label{fig:bestmlp}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                 CONCLUSIONES                                %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusiones}

\par Analizados ambos modelos, estamos en disposición de valorar objetivamente cual de ellos da mejor resultado para el problema que teníamos que resolver: para ello veamos los dos modelos elegidos para cada tipo, y también la tabla de resultados de cada uno de los dos modelos. La diferencia entre ambos modelos es que en Adaline teníamos la posibilidad de modificar ciclos y tasa de aprendizaje mientras que en Perceptrón Multicapa hemos visto que además se pueden añadir capas de neuronas ocultas para hacer el modelo más complejo. El error de test que obtenemos en el mejor modelo escogido por Adaline es de 0.019147481314295 mientras que el error de test que obtenemos en el mejor modelo escogido MLP es de 0.00569856426934457. Como vemos resulta evidente que el error mejora significativamente en un factor de $\frac{1}{4}$ aproximadamente. Consideramos entonces que una red MLP aproxima mejor y es capaz de generalizar mejor en este caso concreto, aunque hay que tener cautela porque es fácil dejarse llevar y añadir las suficientes capas para que MLP aproxime exactamente el conjunto de entrenamiento, que como ya hemos visto en \ref{fig:10050012000tan} no nos lleva más que a una red que posteriormente fallará en la generalización de otros conjuntos de datos.

\par Es importante resaltar que aunque parezca que la diferencia es mínima en cuanto se "desnormalizan" los datos vemos que algunas salidas tanto en \ref{fig:bestmlp} como en \ref{fig:bestadaline} presentan errores de una magnitud bastante importante, y que en estos casos nuestras redes fallan en su generalización.

\par En cuanto a la práctica en general, pienso que ha habido problemas de rendimiento tanto en el script en R como en mi programa en PHP debido a que el proceso de aprendizaje si los ciclos son muy elevados he llegado a ver ejecuciones de veinte minutos. Lo cual ha provocado tener que invertir más tiempo en la práctica. Sería bueno plantearse mejorar el rendimiento de estos programas aunque se entiende que no es el objetivo principal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                BIBLIOGRAFÍA                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{10}


\bibitem{KEEL}
   Conjunto de datos del hormigón, 
   \newblock Knowledge Extraction based on Evolutionary Learning. 
   \newblock Obtenido de
   \url{http://sci2s.ugr.es/keel/dataset.php?cod=44}.

\bibitem{Adaline}
   Primeros modelos computacionales, 
   \newblock Inés M. Galván y José Mª Valls.
   \newblock Obtenido de
   \url{http://ocw.uc3m.es/ingenieria-informatica/redes-de-neuronas-artificiales/transparencias/material-de-clase.-tema-2/view}.

\bibitem{MLP}
   Peceptrón Multicapa, 
   \newblock Inés M. Galván y José Mª Valls.
   \newblock Obtenido de
   \url{http://ocw.uc3m.es/ingenieria-informatica/redes-de-neuronas-artificiales/transparencias/material-de-clase.-tema-3/view}.

\end{thebibliography}
\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                              FI DEL DOCUMENT                                %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
